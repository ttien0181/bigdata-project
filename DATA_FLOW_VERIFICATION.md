# ðŸ” Luá»“ng Hoáº¡t Äá»™ng & Minh Chá»©ng tá»«ng Step

> TÃ i liá»‡u mÃ´ táº£ chi tiáº¿t data flow cá»§a há»‡ thá»‘ng Air Quality Monitoring vÃ  cÃ¡ch kiá»ƒm tra minh chá»©ng tá»«ng bÆ°á»›c.

---

## ðŸ“Š SÆ¡ Ä‘á»“ Luá»“ng Dá»¯ Liá»‡u

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Producer   â”‚  Simulates OpenWeather API
â”‚ (sensor_sim) â”‚  Every 5 seconds
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Publish JSON messages
       â”‚ Topic: air_quality_data
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Kafka     â”‚  Message Queue
â”‚  (Strimzi)   â”‚  Stores messages temporarily
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Subscribe & Stream
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Spark     â”‚  Stream Processing
â”‚  Streaming   â”‚  - Parse JSON
â”‚              â”‚  - Add city mapping
â”‚              â”‚  - Transform schema
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                 â”‚                 â”‚
       â–¼                 â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   HDFS   â”‚      â”‚PostgreSQLâ”‚     â”‚ Console  â”‚
â”‚ Parquet  â”‚      â”‚  Table   â”‚     â”‚  Logs    â”‚
â”‚  Files   â”‚      â”‚          â”‚     â”‚          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚ Grafana  â”‚  Visualization
                 â”‚Dashboard â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ”„ Chi Tiáº¿t tá»«ng Step

### **Step 1: Producer táº¡o dá»¯ liá»‡u giáº£ láº­p**

**Chá»©c nÄƒng:**
- Giáº£ láº­p OpenWeather API
- Táº¡o dá»¯ liá»‡u AQI cho 3 thÃ nh phá»‘: Hanoi, HCM, DaNang
- Publish vÃ o Kafka topic `air_quality_data` má»—i 5 giÃ¢y

**Minh chá»©ng:**

```powershell
# Xem logs producer Ä‘á»ƒ tháº¥y messages Ä‘Æ°á»£c táº¡o
kubectl logs -f deployment/producer -n air-quality --tail=20
```

**Output máº«u:**
```
Publishing message to Kafka topic: air_quality_data
{
  "timestamp_unix": 1768328352,
  "latitude": 21.0285,
  "longitude": 105.8542,
  "aqi": 3,
  "pm2_5": 74.17,
  "pm10": 35.92,
  "co": 203.18,
  "no2": 1.28
}
Message published successfully
Sleeping for 5 seconds...
```

**XÃ¡c nháº­n:** Producer publish JSON messages má»—i 5 giÃ¢y âœ…

---

### **Step 2: Kafka nháº­n vÃ  lÆ°u trá»¯ messages**

**Chá»©c nÄƒng:**
- Nháº­n messages tá»« Producer
- LÆ°u trá»¯ táº¡m thá»i trong topic
- Cung cáº¥p cho Spark consumer

**Minh chá»©ng 1: Xem Kafka topics**

```powershell
kubectl exec -it air-quality-kafka-air-quality-pool-0 -n air-quality -- \
  /opt/kafka/bin/kafka-topics.sh \
  --list \
  --bootstrap-server localhost:29092
```

**Output máº«u:**
```
air_quality_data
__consumer_offsets
```

**Minh chá»©ng 2: Consume messages tá»« topic**

```powershell
kubectl exec -it air-quality-kafka-air-quality-pool-0 -n air-quality -- \
  /opt/kafka/bin/kafka-console-consumer.sh \
  --bootstrap-server localhost:29092 \
  --topic air_quality_data \
  --from-beginning \
  --max-messages 5
```

**Output máº«u:**
```
{"timestamp_unix":1768328352,"latitude":21.0285,"longitude":105.8542,"aqi":3,"pm2_5":74.17,...}
{"timestamp_unix":1768328357,"latitude":10.8231,"longitude":106.6297,"aqi":5,"pm2_5":150.66,...}
{"timestamp_unix":1768328362,"latitude":16.0544,"longitude":108.2022,"aqi":1,"pm2_5":19.14,...}
Processed a total of 5 messages
```

**XÃ¡c nháº­n:** Kafka lÆ°u trá»¯ messages thÃ nh cÃ´ng âœ…

---

### **Step 3: Spark Streaming Ä‘á»c vÃ  xá»­ lÃ½**

**Chá»©c nÄƒng:**
- Subscribe Kafka topic `air_quality_data`
- Parse JSON schema
- Transform: thÃªm cá»™t `city` (Hanoi/HCM/DaNang), `timestamp`, `ingested_at`
- Cháº¡y micro-batch má»—i 5 giÃ¢y

**Minh chá»©ng 1: Xem Spark logs processing**

```powershell
kubectl logs -f deployment/spark-processor -n air-quality --tail=50
```

**Output máº«u:**
```
>>> Äang xá»­ lÃ½ dá»¯ liá»‡u tá»« OpenWeatherMap API giáº£ láº­p...

=== Batch 1 ===
+--------------+-----------------------+---------+--------+---+------+-----+------+----+
|timestamp_unix|processed_time         |longitude|latitude|aqi|pm2_5 |pm10 |co    |no2 |
+--------------+-----------------------+---------+--------+---+------+-----+------+----+
|1768328352    |2026-01-13 18:18:48.643|105.8542 |21.0285 |3  |74.17 |35.92|203.18|1.28|
|1768328352    |2026-01-13 18:18:48.643|106.6297 |10.8231 |3  |100.83|18.59|299.89|0.55|
|1768328352    |2026-01-13 18:18:48.643|108.2022 |16.0544 |3  |61.48 |20.39|204.61|0.71|
+--------------+-----------------------+---------+--------+---+------+-----+------+----+

=== Batch 2 ===
...
```

**Minh chá»©ng 2: Kiá»ƒm tra Spark application status**

```powershell
# Má»Ÿ Spark Master UI
minikube service spark-master -n air-quality
# Truy cáº­p: http://MINIKUBE_IP:30080
```

**Trong UI:**
- **Running Applications**: `OpenWeatherProcessor` (Status: RUNNING)
- **Executors**: 2 executors Ä‘ang active
- **Cores Used**: 2/2

**XÃ¡c nháº­n:** Spark Ä‘á»c Kafka vÃ  process batches thÃ nh cÃ´ng âœ…

---

### **Step 4: Ghi dá»¯ liá»‡u vÃ o HDFS (Parquet)**

**Chá»©c nÄƒng:**
- Sau khi transform, Spark ghi Parquet files vÃ o HDFS
- Path: `/data/air_quality_v2/`
- Format: Snappy-compressed Parquet

**Minh chá»©ng 1: Liá»‡t kÃª files trong HDFS**

```powershell
kubectl exec -it namenode-0 -n air-quality -- \
  hdfs dfs -ls /data/air_quality_v2
```

**Output máº«u:**
```
Found 7 items
-rw-r--r--   3 root supergroup          0 2026-01-13 18:19 /data/air_quality_v2/_SUCCESS
drwxr-xr-x   - root supergroup          0 2026-01-12 17:57 /data/air_quality_v2/_spark_metadata
-rw-r--r--   3 root supergroup       2925 2026-01-13 18:19 /data/air_quality_v2/part-00000-1c37afdb-...snappy.parquet
-rw-r--r--   3 root supergroup     150758 2026-01-13 18:18 /data/air_quality_v2/part-00000-26569eed-...snappy.parquet
-rw-r--r--   3 root supergroup       1038 2026-01-13 18:18 /data/air_quality_v2/part-00000-8026f422-...snappy.parquet
```

**Minh chá»©ng 2: Äá»c ná»™i dung Parquet file (sample)**

```powershell
kubectl exec -it namenode-0 -n air-quality -- \
  hdfs dfs -cat /data/air_quality_v2/part-00000-*.parquet | head -c 200
```

**Output:** Binary Parquet data (khÃ´ng Ä‘á»c Ä‘Æ°á»£c text, chá»©ng tá» Ä‘Ãºng format)

**Minh chá»©ng 3: Xem HDFS NameNode UI**

```powershell
minikube service namenode -n air-quality
# Truy cáº­p: http://MINIKUBE_IP:30870
```

**Trong UI:**
- **Utilities â†’ Browse the file system**
- Navigate: `/data/air_quality_v2/`
- Tháº¥y danh sÃ¡ch Parquet files vá»›i size > 0

**XÃ¡c nháº­n:** Parquet files Ä‘Æ°á»£c ghi vÃ o HDFS thÃ nh cÃ´ng âœ…

---

### **Step 5: Ghi dá»¯ liá»‡u vÃ o PostgreSQL**

**Chá»©c nÄƒng:**
- Spark ghi cÃ¹ng dá»¯ liá»‡u vÃ o PostgreSQL
- Database: `air_quality`
- Table: `air_quality_final`
- Schema: `timestamp`, `city`, `aqi`, `pm2_5`, `pm10`, `co`, `no2`, `ingested_at`

**Minh chá»©ng 1: Äáº¿m sá»‘ records**

```powershell
kubectl exec -it postgres-0 -n air-quality -- \
  psql -U admin -d air_quality -c "SELECT COUNT(*) FROM air_quality_final;"
```

**Output máº«u:**
```
 count
-------
  8241
(1 row)
```

**Minh chá»©ng 2: Xem sample data**

```powershell
kubectl exec -it postgres-0 -n air-quality -- \
  psql -U admin -d air_quality -c \
  "SELECT city, timestamp, aqi, pm2_5, ingested_at FROM air_quality_final ORDER BY ingested_at DESC LIMIT 5;"
```

**Output máº«u:**
```
  city  |      timestamp      | aqi | pm2_5  |       ingested_at
--------+---------------------+-----+--------+-------------------------
 Hanoi  | 2026-01-13 18:19:36 |   3 | 119.87 | 2026-01-13 18:19:36.182
 HCM    | 2026-01-13 18:19:36 |   1 |  18.70 | 2026-01-13 18:19:36.182
 DaNang | 2026-01-13 18:19:36 |   3 |  50.15 | 2026-01-13 18:19:36.182
 Hanoi  | 2026-01-13 18:19:31 |   3 | 140.51 | 2026-01-13 18:19:31.167
 HCM    | 2026-01-13 18:19:31 |   3 | 141.04 | 2026-01-13 18:19:31.167
```

**Minh chá»©ng 3: PhÃ¢n tÃ­ch theo city**

```powershell
kubectl exec -it postgres-0 -n air-quality -- \
  psql -U admin -d air_quality -c \
  "SELECT city, COUNT(*) as count, ROUND(AVG(aqi), 2) as avg_aqi FROM air_quality_final GROUP BY city ORDER BY city;"
```

**Output máº«u:**
```
  city  | count | avg_aqi
--------+-------+---------
 DaNang |  2741 |    3.03
 Hanoi  |  2741 |    3.02
 HCM    |  2741 |    3.00
(3 rows)
```

**XÃ¡c nháº­n:**
- PostgreSQL nháº­n dá»¯ liá»‡u liÃªn tá»¥c âœ…
- Dá»¯ liá»‡u phÃ¢n bá»‘ Ä‘á»u cho 3 thÃ nh phá»‘ âœ…
- Trung bÃ¬nh AQI ~3 (há»£p lÃ½ vá»›i dá»¯ liá»‡u giáº£ láº­p) âœ…

---

### **Step 6: Grafana hiá»ƒn thá»‹ dashboard**

**Chá»©c nÄƒng:**
- Káº¿t ná»‘i PostgreSQL
- Query dá»¯ liá»‡u real-time
- Visualize: Time-series charts, tables, heatmaps

**Minh chá»©ng 1: Truy cáº­p Grafana**

```powershell
minikube service grafana -n air-quality
# URL: http://MINIKUBE_IP:30300
# Login: admin / admin123
```

**Minh chá»©ng 2: Setup PostgreSQL Data Source (Náº¿u chÆ°a cÃ³)**

> **LÆ°u Ã½:** Náº¿u vÃ o Grafana láº§n Ä‘áº§u chÆ°a tháº¥y datasource, lÃ m theo cÃ¡c bÆ°á»›c sau:

1. **VÃ o Configuration â†’ Data Sources**
   - Click **Configuration** (cog icon) â†’ **Data Sources**
   - Click **Add data source**

2. **Chá»n PostgreSQL**
   - Search: "PostgreSQL"
   - Click **PostgreSQL**

3. **Äiá»n thÃ´ng tin káº¿t ná»‘i**
   ```
   Name: PostgreSQL Air Quality (hoáº·c tÃªn báº¥t ká»³)
   Host: postgres:5432
   Database: air_quality
   User: admin
   Password: password123
   SSL Mode: disable
   ```
   
   **Chi tiáº¿t cÃ¡c field:**
   - **Host**: TÃªn service Kubernetes + port (postgres lÃ  service name)
   - **Database**: `air_quality` (do secret setup)
   - **User**: `admin` (do secret setup)
   - **Password**: `password123` (do secret setup)
   - **SSL Mode**: `disable` (local network, khÃ´ng cáº§n SSL)

4. **Test Connection**
   - Click **Save & Test**
   - Náº¿u tháº¥y "Database Connection OK" â†’ âœ… Success

5. **Troubleshooting náº¿u connection fail:**
   
   ```powershell
   # Kiá»ƒm tra PostgreSQL pod running
   kubectl get pods -n air-quality | findstr postgres
   
   # Kiá»ƒm tra service
   kubectl get svc -n air-quality | findstr postgres
   
   # Test connection tá»« Grafana pod
   kubectl exec -it grafana-* -n air-quality -- \
     psql -h postgres -p 5432 -U admin -d air_quality -c "SELECT 1"
   ```

**Minh chá»©ng 3: Táº¡o Dashboard (Tá»« scratch)**

Náº¿u chÆ°a cÃ³ dashboard "Air Quality Monitoring", táº¡o má»›i:

1. **Táº¡o Dashboard má»›i**
   - Click **Create â†’ Dashboard**
   - Click **Add panel**

2. **Panel 1: Time-series Chart (PM2.5 trends)**
   
   **Query:**
   ```sql
   SELECT
     ingested_at as time,
     pm2_5,
     city
   FROM air_quality_final
   WHERE ingested_at > now() - interval '1 hour'
   ORDER BY ingested_at
   ```
   
   **Panel Settings:**
   - **Title**: PM2.5 Trends
   - **Type**: Time series
   - **Axes â†’ Y-axis**: Min 0, Max 200
   - **Legend**: Show (Multiple)
   - **Refresh**: Auto 5s

3. **Panel 2: Table (Latest values)**
   
   **Query:**
   ```sql
   SELECT
     city,
     ROUND(AVG(aqi), 2) as aqi,
     ROUND(AVG(pm2_5), 2) as pm2_5,
     ROUND(AVG(pm10), 2) as pm10,
     MAX(ingested_at) as last_update
   FROM air_quality_final
   WHERE ingested_at > now() - interval '5 minutes'
   GROUP BY city
   ORDER BY city
   ```
   
   **Panel Settings:**
   - **Title**: Latest Readings
   - **Type**: Table
   - **Column width**: Auto

4. **Panel 3: Gauge (Current AQI)**
   
   **Query:**
   ```sql
   SELECT
     ROUND(AVG(aqi), 0) as aqi_avg
   FROM air_quality_final
   WHERE ingested_at > now() - interval '1 minute'
   ```
   
   **Panel Settings:**
   - **Title**: Current AQI (All cities)
   - **Type**: Gauge
   - **Thresholds**: Green (0-50), Yellow (50-100), Red (100+)
   - **Unit**: None

5. **Save Dashboard**
   - Click **Save** (Ctrl+S)
   - Name: "Air Quality Monitoring"
   - Folder: "General"

**Minh chá»©ng 4: Xem Dashboard cháº¡y**

- Dashboard auto-refresh má»—i 5s
- Tháº¥y 3 lines PM2.5: Hanoi, HCM, DaNang
- Table cáº­p nháº­t vá»›i latest readings
- Gauge thay Ä‘á»•i theo real-time AQI

**XÃ¡c nháº­n:** Grafana hiá»ƒn thá»‹ dá»¯ liá»‡u real-time thÃ nh cÃ´ng âœ…

---

## ðŸ§ª Test E2E Flow (End-to-End)

### Test Scenario: Táº¡o dá»¯ liá»‡u má»›i â†’ Xuáº¥t hiá»‡n trong táº¥t cáº£ outputs

**BÆ°á»›c 1: Ghi láº¡i timestamp hiá»‡n táº¡i**

```powershell
# Xem batch gáº§n nháº¥t
kubectl logs deployment/spark-processor -n air-quality --tail=20 | Select-String "Batch"
# Output: === Batch 125 ===
```

**BÆ°á»›c 2: Äá»£i 10 giÃ¢y (2 batches)**

```powershell
Start-Sleep -Seconds 10
```

**BÆ°á»›c 3: Kiá»ƒm tra Kafka cÃ³ message má»›i**

```powershell
kubectl exec -it air-quality-kafka-air-quality-pool-0 -n air-quality -- \
  /opt/kafka/bin/kafka-console-consumer.sh \
  --bootstrap-server localhost:29092 \
  --topic air_quality_data \
  --max-messages 3 \
  --from-beginning
```

**BÆ°á»›c 4: Kiá»ƒm tra Spark Ä‘Ã£ process**

```powershell
kubectl logs deployment/spark-processor -n air-quality --tail=20 | Select-String "Batch"
# Output: === Batch 127 === (tÄƒng lÃªn)
```

**BÆ°á»›c 5: Kiá»ƒm tra HDFS cÃ³ file má»›i**

```powershell
kubectl exec -it namenode-0 -n air-quality -- \
  hdfs dfs -ls -t /data/air_quality_v2/ | head -5
# File má»›i nháº¥t sáº½ á»Ÿ trÃªn cÃ¹ng
```

**BÆ°á»›c 6: Kiá»ƒm tra PostgreSQL count tÄƒng**

```powershell
# Count trÆ°á»›c
kubectl exec -it postgres-0 -n air-quality -- \
  psql -U admin -d air_quality -c "SELECT COUNT(*) FROM air_quality_final;"
# Output: 8241

# Äá»£i 10s
Start-Sleep -Seconds 10

# Count sau
kubectl exec -it postgres-0 -n air-quality -- \
  psql -U admin -d air_quality -c "SELECT COUNT(*) FROM air_quality_final;"
# Output: 8250+ (tÄƒng lÃªn)
```

**BÆ°á»›c 7: Xem Grafana dashboard refresh**

- Má»Ÿ Grafana UI
- Dashboard tá»± Ä‘á»™ng refresh
- Tháº¥y Ä‘iá»ƒm dá»¯ liá»‡u má»›i xuáº¥t hiá»‡n trÃªn chart

**âœ… Káº¿t luáº­n:** Dá»¯ liá»‡u flow tá»« Producer â†’ Kafka â†’ Spark â†’ HDFS/PostgreSQL/Grafana hoÃ n toÃ n tá»± Ä‘á»™ng!

---

## ðŸ“ˆ Metrics & Monitoring

### Resource Usage

```powershell
# CPU/Memory cá»§a pods
kubectl top pods -n air-quality
```

**Output máº«u:**
```
NAME                               CPU(cores)   MEMORY(bytes)
kafka-0                            45m          1024Mi
namenode-0                         25m          768Mi
postgres-0                         18m          234Mi
producer-6b9c8d7f5e-8jhg7          5m           128Mi
spark-master-5c4d6e8f9a-2nkl3      32m          512Mi
spark-processor-68cb7dcd78-7w2wm   65m          1580Mi
spark-worker-6c8d788744-24jtx      28m          678Mi
```

### Kafka Lag (Consumer Ä‘á»c ká»‹p Producer khÃ´ng?)

```powershell
kubectl exec -it air-quality-kafka-air-quality-pool-0 -n air-quality -- \
  /opt/kafka/bin/kafka-consumer-groups.sh \
  --bootstrap-server localhost:29092 \
  --describe \
  --group spark-kafka-source-*
```

**Output máº«u:**
```
GROUP                  TOPIC             PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG
spark-kafka-source-... air_quality_data  0          12450           12450           0
```

**LAG = 0** â†’ Spark Ä‘á»c ká»‹p Producer, khÃ´ng bá»‹ tá»¥t háº­u âœ…

---

## ðŸš¨ Troubleshooting Common Issues

### Issue 1: Spark logs khÃ´ng tháº¥y batch má»›i

**Kiá»ƒm tra:**
```powershell
kubectl logs deployment/spark-processor -n air-quality --tail=100 | Select-String "error|Error|Exception"
```

**NguyÃªn nhÃ¢n thÆ°á»ng gáº·p:**
- Kafka topic khÃ´ng tá»“n táº¡i
- Spark executors crash (xem worker logs)
- Out of memory

### Issue 2: PostgreSQL khÃ´ng nháº­n data

**Kiá»ƒm tra:**
```powershell
kubectl exec -it postgres-0 -n air-quality -- \
  psql -U admin -d air_quality -c "\dt"
# Verify table air_quality_final tá»“n táº¡i
```

**NguyÃªn nhÃ¢n:**
- Table chÆ°a Ä‘Æ°á»£c táº¡o (Spark sáº½ táº¡o tá»± Ä‘á»™ng láº§n Ä‘áº§u)
- Connection string sai
- Credentials sai

### Issue 3: HDFS khÃ´ng cÃ³ file

**Kiá»ƒm tra:**
```powershell
kubectl exec -it namenode-0 -n air-quality -- \
  hdfs dfs -ls /data/
# Verify /data/air_quality_v2 tá»“n táº¡i
```

**NguyÃªn nhÃ¢n:**
- NameNode chÆ°a sáºµn sÃ ng
- Permission denied
- Disk full

---

## ðŸ“ Summary Checklist

Äá»ƒ verify toÃ n bá»™ flow hoáº¡t Ä‘á»™ng:

- [x] Producer logs hiá»ƒn thá»‹ "Message published successfully"
- [x] Kafka topic `air_quality_data` cÃ³ messages
- [x] Spark logs hiá»ƒn thá»‹ "=== Batch X ===" tÄƒng dáº§n
- [x] HDFS cÃ³ Parquet files trong `/data/air_quality_v2/`
- [x] PostgreSQL table `air_quality_final` cÃ³ records > 0
- [x] PostgreSQL count tÄƒng má»—i 5 giÃ¢y
- [x] Grafana dashboard hiá»ƒn thá»‹ time-series charts
- [x] Kafka consumer lag = 0

**Náº¿u táº¥t cáº£ âœ… â†’ Há»‡ thá»‘ng hoáº¡t Ä‘á»™ng hoÃ n háº£o!** ðŸŽ‰
