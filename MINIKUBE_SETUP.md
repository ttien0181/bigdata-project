# üöÄ H∆∞·ªõng D·∫´n Chi Ti·∫øt: Ch·∫°y Air Quality Project tr√™n Minikube (Windows)

> H∆∞·ªõng d·∫´n t·ª´ng b∆∞·ªõc v·ªõi output m·∫´u ƒë·ªÉ deploy Big Data Air Quality monitoring system l√™n Kubernetes (Minikube)

---

## üìã Y√™u c·∫ßu H·ªá Th·ªëng

- **OS**: Windows 10/11 (Pro, Enterprise ho·∫∑c Home v·ªõi WSL2)
- **RAM**: T·ªëi thi·ªÉu 12GB (8GB cho Minikube, 4GB cho Windows)
- **CPU**: 4 cores tr·ªü l√™n
- **Disk**: 40GB dung l∆∞·ª£ng tr·ªëng
- **Internet**: ƒê·ªÉ t·∫£i images v√† dependencies

---

## üì¶ C√°c C√¥ng C·ª• C·∫ßn Thi·∫øt

| C√¥ng c·ª• | Phi√™n b·∫£n | M·ª•c ƒë√≠ch |
|---------|-----------|----------|
| Minikube | v1.35+ | Kubernetes cluster local |
| kubectl | v1.31+ | Qu·∫£n l√Ω Kubernetes |
| Docker Desktop | v27+ | Build & run containers |
| PowerShell | 5.1+ ho·∫∑c 7+ | Ch·∫°y scripts |

---

## 1Ô∏è‚É£ B∆Ø·ªöC 1: C√†i ƒê·∫∑t Prerequisites

### 1.1 C√†i ƒë·∫∑t Minikube

**Download Minikube:**
```powershell
# M·ªü PowerShell as Administrator
# Gi·∫£i th√≠ch: T·∫£i file c√†i ƒë·∫∑t Minikube phi√™n b·∫£n m·ªõi nh·∫•t cho Windows
Invoke-WebRequest -OutFile 'minikube.exe' -Uri 'https://github.com/kubernetes/minikube/releases/latest/download/minikube-windows-amd64.exe' -UseBasicParsing

# Gi·∫£i th√≠ch: T·∫°o th∆∞ m·ª•c C:\minikube v√† th√™m v√†o system PATH ƒë·ªÉ ch·∫°y minikube t·ª´ b·∫•t k·ª≥ ƒë√¢u
New-Item -Path 'C:\minikube' -Type Directory -Force
Move-Item 'minikube.exe' 'C:\minikube\minikube.exe'
$env:Path += ";C:\minikube"
[Environment]::SetEnvironmentVariable("Path", $env:Path, [System.EnvironmentVariableTarget]::Machine)
```

**Output m·∫´u:**
```
Directory: C:\

Mode                 LastWriteTime         Length Name
----                 -------------         ------ ----
d-----        1/12/2026   3:30 PM                minikube
```

**Ki·ªÉm tra c√†i ƒë·∫∑t:**
```powershell
# Gi·∫£i th√≠ch: Hi·ªÉn th·ªã phi√™n b·∫£n Minikube ƒë√£ c√†i ƒë·ªÉ x√°c nh·∫≠n c√†i ƒë·∫∑t th√†nh c√¥ng
minikube version
```

**Output m·∫´u:**
```
minikube version: v1.35.0
commit: dd5d320e41b5451cdf3c01891bc4e13d189586ed
```

---

### 1.2 C√†i ƒë·∫∑t kubectl

```powershell
# Gi·∫£i th√≠ch: T·∫£i kubectl - c√¥ng c·ª• command-line ƒë·ªÉ qu·∫£n l√Ω Kubernetes cluster
curl.exe -LO "https://dl.k8s.io/release/v1.32.0/bin/windows/amd64/kubectl.exe"

# Gi·∫£i th√≠ch: Di chuy·ªÉn kubectl.exe v√†o th∆∞ m·ª•c C:\minikube (ƒë√£ c√≥ trong PATH)
Move-Item kubectl.exe C:\minikube\kubectl.exe
```

**Ki·ªÉm tra:**
```powershell
# Gi·∫£i th√≠ch: Hi·ªÉn th·ªã phi√™n b·∫£n kubectl client ƒë·ªÉ x√°c nh·∫≠n c√†i ƒë·∫∑t th√†nh c√¥ng
kubectl version --client
```

**Output m·∫´u:**
```
Client Version: v1.32.3
Kustomize Version: v5.0.4-0.20230601165947-6ce0bf390ce3
```

---

### 1.3 C√†i ƒë·∫∑t Docker Desktop

1. T·∫£i t·ª´: https://www.docker.com/products/docker-desktop
2. Ch·∫°y installer
3. Kh·ªüi ƒë·ªông l·∫°i Windows
4. M·ªü Docker Desktop v√† ch·ªù kh·ªüi ƒë·ªông

**Ki·ªÉm tra:**
```powershell
# Gi·∫£i th√≠ch: Hi·ªÉn th·ªã phi√™n b·∫£n Docker client v√† server ƒë·ªÉ x√°c nh·∫≠n Docker Desktop ƒë√£ ch·∫°y
docker version
```

**Output m·∫´u:**
```
Client:
 Version:           27.5.1
 API version:       1.47
 Go version:        go1.22.10
 Git commit:        7de81f1
 Built:             Wed Dec 18 15:21:25 2024
 OS/Arch:           windows/amd64
 Context:           default

Server: Docker Desktop 4.37.4 (178371)
 Engine:
  Version:          27.5.1
  API version:      1.47 (minimum version 1.24)
  Go version:       go1.22.10
  Git commit:       48c5c73
  Built:            Wed Dec 18 15:21:30 2024
  OS/Arch:          linux/amd64
```

---

## 2Ô∏è‚É£ B∆Ø·ªöC 2: Kh·ªüi ƒê·ªông Minikube Cluster

### 2.1 Start Minikube v·ªõi c·∫•u h√¨nh ph√π h·ª£p

```powershell
# Gi·∫£i th√≠ch: Kh·ªüi ƒë·ªông Minikube cluster v·ªõi 4 CPUs, 8GB RAM, 30GB disk, s·ª≠ d·ª•ng Docker driver
# L∆∞u √Ω: Ch·∫°y trong PowerShell Administrator, ho·∫∑c trong VSCode v·ªõi quy·ªÅn admin
minikube start --cpus=4 --memory=8192 --disk-size=30g --driver=docker
```

**Output m·∫´u:**
```
üòÑ  minikube v1.35.0 on Microsoft Windows 11 Home 10.0.26100.7462
‚ú®  Using the docker driver based on user configuration
üìå  Using Docker Desktop driver with root privileges
üëç  Starting "minikube" primary control-plane node in "minikube" cluster
üöú  Pulling base image v0.0.45 ...
üî•  Creating docker container (CPUs=4, Memory=8192MB) ...
üê≥  Preparing Kubernetes v1.31.0 on Docker 27.3.1 ...
    ‚ñ™ Generating certificates and keys ...
    ‚ñ™ Booting up control plane ...
    ‚ñ™ Configuring RBAC rules ...
üîó  Configuring bridge CNI (Container Networking Interface) ...
üîé  Verifying Kubernetes components...
    ‚ñ™ Using image gcr.io/k8s-minikube/storage-provisioner:v5
üåü  Enabled addons: storage-provisioner, default-storageclass
üèÑ  Done! kubectl is now configured to use "minikube" cluster and "default" namespace by default
```

**Th·ªùi gian**: ~3-5 ph√∫t l·∫ßn ƒë·∫ßu (t√πy t·ªëc ƒë·ªô internet)

---

### 2.2 Ki·ªÉm tra Minikube status

```powershell
# Gi·∫£i th√≠ch: Hi·ªÉn th·ªã tr·∫°ng th√°i c·ªßa Minikube cluster (host, kubelet, apiserver)
minikube status
```

**Output m·∫´u:**
```
minikube
type: Control Plane
host: Running
kubelet: Running
apiserver: Running
kubeconfig: Configured
```

---

### 2.3 Ki·ªÉm tra Kubernetes cluster

```powershell
# Gi·∫£i th√≠ch: Hi·ªÉn th·ªã th√¥ng tin cluster (API server URL, CoreDNS URL)
kubectl cluster-info
```

**Output m·∫´u:**
```
Kubernetes control plane is running at https://127.0.0.1:51812
CoreDNS is running at https://127.0.0.1:51812/api/v1/namespaces/kube-system/services/kube-dns:dns/proxy

To further debug and diagnose cluster problems, use 'kubectl cluster-info dump'.
```

---

### 2.4 L·∫•y Minikube IP

```powershell
# Gi·∫£i th√≠ch: Hi·ªÉn th·ªã ƒë·ªãa ch·ªâ IP c·ªßa Minikube cluster ƒë·ªÉ truy c·∫≠p services qua NodePort
minikube ip
```

**Output m·∫´u:**
```
192.168.49.2
```

> ‚ö†Ô∏è **L∆∞u IP n√†y** - B·∫°n s·∫Ω d√πng ƒë·ªÉ truy c·∫≠p services qua NodePort

---

### 2.5 Enable Kubernetes Addons

```powershell
# Gi·∫£i th√≠ch: B·∫≠t addon storage-provisioner ƒë·ªÉ t·ª± ƒë·ªông t·∫°o PersistentVolumes
minikube addons enable storage-provisioner

# Gi·∫£i th√≠ch: B·∫≠t addon metrics-server ƒë·ªÉ xem CPU/Memory usage c·ªßa nodes v√† pods
minikube addons enable metrics-server
```

**Output m·∫´u:**
```
üí°  storage-provisioner is an addon maintained by minikube. For any concerns contact minikube on GitHub.
You can view the list of minikube maintainers at: https://github.com/kubernetes/minikube/blob/master/OWNERS
    ‚ñ™ Using image gcr.io/k8s-minikube/storage-provisioner:v5
üåü  The 'storage-provisioner' addon is enabled

üí°  metrics-server is an addon maintained by Kubernetes. For any concerns contact minikube on GitHub.
You can view the list of minikube maintainers at: https://github.com/kubernetes/minikube/blob/master/OWNERS
    ‚ñ™ Using image registry.k8s.io/metrics-server/metrics-server:v0.7.2
üåü  The 'metrics-server' addon is enabled
```

---

## 3Ô∏è‚É£ B∆Ø·ªöC 3: Build Docker Images cho Project

### 3.1 Point Docker CLI t·ªõi Minikube

```powershell
# Gi·∫£i th√≠ch: Chuy·ªÉn Docker CLI sang Docker daemon c·ªßa Minikube ƒë·ªÉ build images tr·ª±c ti·∫øp trong cluster
# Quan tr·ªçng: Sau l·ªánh n√†y, m·ªçi docker commands s·∫Ω ch·∫°y trong Minikube, kh√¥ng ph·∫£i Docker Desktop
minikube -p minikube docker-env | Invoke-Expression
```

**Output m·∫´u:**
```
$Env:DOCKER_TLS_VERIFY = "1"
$Env:DOCKER_HOST = "tcp://192.168.49.2:2376"
$Env:DOCKER_CERT_PATH = "C:\Users\YourUser\.minikube\certs"
$Env:MINIKUBE_ACTIVE_DOCKERD = "minikube"
# To point your shell to minikube's docker-daemon, run:
# & minikube -p minikube docker-env --shell powershell | Invoke-Expression
```

> üí° **Quan tr·ªçng**: Sau khi ch·∫°y l·ªánh n√†y, t·∫•t c·∫£ docker commands s·∫Ω ch·∫°y trong Minikube VM, kh√¥ng ph·∫£i Docker Desktop!

---

### 3.2 Di chuy·ªÉn v√†o th∆∞ m·ª•c project

```powershell
# Gi·∫£i th√≠ch: Di chuy·ªÉn v√†o th∆∞ m·ª•c ch·ª©a source code c·ªßa project
# L∆∞u √Ω: Thay ƒë·ªïi ƒë∆∞·ªùng d·∫´n cho ph√π h·ª£p v·ªõi m√°y c·ªßa b·∫°n
cd D:\BigData\bigdata
```

---

### 3.3 Build Producer Image

```powershell
# Gi·∫£i th√≠ch: Build Docker image cho Producer t·ª´ Dockerfile trong th∆∞ m·ª•c ./producer
# Image ƒë∆∞·ª£c tag l√† air-producer:latest ƒë·ªÉ s·ª≠ d·ª•ng trong K8s manifests
docker build -t air-producer:latest ./producer
```

**Output m·∫´u:**
```
[+] Building 45.2s (10/10) FINISHED
 => [internal] load build definition from Dockerfile                      0.0s
 => => transferring dockerfile: 456B                                      0.0s
 => [internal] load metadata for docker.io/library/python:3.9-slim        2.1s
 => [internal] load .dockerignore                                         0.0s
 => => transferring context: 2B                                           0.0s
 => [1/5] FROM docker.io/library/python:3.9-slim@sha256:abc123...        15.4s
 => [internal] load build context                                         0.1s
 => => transferring context: 4.52kB                                       0.0s
 => [2/5] WORKDIR /app                                                    0.3s
 => [3/5] COPY requirements.txt .                                         0.0s
 => [4/5] RUN pip install --no-cache-dir -r requirements.txt             25.8s
 => [5/5] COPY sensor_sim.py .                                            0.0s
 => exporting to image                                                    1.5s
 => => exporting layers                                                   1.4s
 => => writing image sha256:def456...                                     0.0s
 => => naming to docker.io/library/air-producer:latest                   0.0s
```

**Th·ªùi gian**: ~30-60 gi√¢y (l·∫ßn ƒë·∫ßu ~2-3 ph√∫t)

---

### 3.4 Build Spark Processor Image

```powershell
# Gi·∫£i th√≠ch: Build Docker image cho Spark Processor t·ª´ Dockerfile trong th∆∞ m·ª•c ./spark-processor
# Image ƒë∆∞·ª£c tag l√† spark-processor:latest ƒë·ªÉ s·ª≠ d·ª•ng trong K8s manifests
docker build -t spark-processor:latest ./spark-processor
```

**Output m·∫´u:**
```
[+] Building 78.5s (12/12) FINISHED
 => [internal] load build definition from Dockerfile                      0.0s
 => => transferring dockerfile: 612B                                      0.0s
 => [internal] load metadata for docker.io/bitnami/spark:3.0              3.2s
 => [1/7] FROM docker.io/bitnami/spark:3.0@sha256:xyz789...              35.2s
 => [internal] load build context                                         0.2s
 => => transferring context: 15.3kB                                       0.1s
 => [2/7] USER root                                                       0.5s
 => [3/7] WORKDIR /app                                                    0.3s
 => [4/7] COPY stream_app.py .                                            0.1s
 => [5/7] COPY viewer.py .                                                0.0s
 => [6/7] COPY libs/ /opt/bitnami/spark/jars/                             0.2s
 => [7/7] RUN chmod +x stream_app.py viewer.py                            0.8s
 => exporting to image                                                    2.1s
 => => exporting layers                                                   2.0s
 => => writing image sha256:uvw012...                                     0.0s
 => => naming to docker.io/library/spark-processor:latest                0.0s
```

---

### 3.5 Verify Images

```powershell
# Gi·∫£i th√≠ch: Li·ªát k√™ c√°c Docker images ƒë√£ build ƒë·ªÉ x√°c nh·∫≠n air-producer v√† spark-processor t·ªìn t·∫°i
docker images | findstr "air-producer spark-processor"
```

**Output m·∫´u:**
```
air-producer       latest    def456789abc   2 minutes ago   456MB
spark-processor    latest    uvw012345xyz   1 minute ago    823MB
```

---

## 4Ô∏è‚É£ B∆Ø·ªöC 4: Deploy Application l√™n Kubernetes

### 4.1 T·∫°o Namespace

```powershell
# Gi·∫£i th√≠ch: T·∫°o namespace air-quality ƒë·ªÉ c√¥ l·∫≠p resources c·ªßa project v·ªõi c√°c nh√≥m kh√°c
kubectl create namespace air-quality
```

**Output m·∫´u:**
```
namespace/air-quality created
```

**Set default namespace:**
```powershell
# Gi·∫£i th√≠ch: ƒê·∫∑t air-quality l√†m namespace m·∫∑c ƒë·ªãnh ƒë·ªÉ kh√¥ng c·∫ßn g√µ -n air-quality trong m·ªçi l·ªánh
kubectl config set-context --current --namespace=air-quality
```

**Output m·∫´u:**
```
Context "minikube" modified.
```

---

### 4.2 Deploy t·∫•t c·∫£ Kubernetes manifests

```powershell
# Gi·∫£i th√≠ch: Apply c√°c file YAML theo th·ª© t·ª± ƒë·ªÉ t·∫°o ConfigMaps, Secrets, PVs, Services, Deployments, StatefulSets
# Ch√∫ √Ω: Ch·∫°y t·ª´ng l·ªánh theo th·ª© t·ª±, kh√¥ng ch·∫°y c√πng l√∫c
kubectl apply -f k8s/00-namespace-config.yaml
kubectl apply -f k8s/01-services.yaml
kubectl apply -f k8s/kafka-strimzi.yaml
kubectl apply -f k8s/03-hadoop.yaml
kubectl apply -f k8s/04-spark.yaml
kubectl apply -f k8s/05-database.yaml
kubectl apply -f k8s/06-applications.yaml
```

> üí° **L∆∞u √Ω:** S·ª≠ d·ª•ng `kafka-strimzi.yaml` (Strimzi Kafka Operator) thay v√¨ `02-kafka.yaml` (Confluent). Strimzi l√† gi·∫£i ph√°p Kubernetes-native ·ªïn ƒë·ªãnh.

**Output m·∫´u:**
```
namespace/air-quality unchanged
configmap/hadoop-config created
secret/postgres-secret created
secret/openweather-secret created
persistentvolume/namenode-pv created
persistentvolume/datanode-pv created
persistentvolume/postgres-pv created
persistentvolume/zookeeper-pv created
persistentvolume/kafka-pv created

service/zookeeper created
service/kafka created
service/kafka-headless created
service/namenode created
service/datanode created
service/spark-master created
service/spark-worker created
service/postgres created
service/grafana created

statefulset.apps/zookeeper created
statefulset.apps/kafka created

statefulset.apps/namenode created
statefulset.apps/datanode created

deployment.apps/spark-master created
deployment.apps/spark-worker created

statefulset.apps/postgres created
deployment.apps/grafana created

deployment.apps/producer created
deployment.apps/spark-processor created
service/spark-processor created
```

---

### 4.3 Ki·ªÉm tra Pods ƒëang kh·ªüi ƒë·ªông

```powershell
# Gi·∫£i th√≠ch: Theo d√µi tr·∫°ng th√°i pods realtime (-w = watch mode), nh·∫•n Ctrl+C ƒë·ªÉ tho√°t
kubectl get pods -w
```

**Output m·∫´u (ban ƒë·∫ßu):**
```
NAME                                        READY   STATUS              RESTARTS   AGE
air-quality-kafka-air-quality-pool-0        0/1     ContainerCreating   0          10s
datanode-0                                  0/1     ContainerCreating   0          5s
datanode-1                                  0/1     Pending             0          5s
grafana-7d5b8f6c9d-4xk2m                    0/1     ContainerCreating   0          5s
namenode-0                                  0/1     ContainerCreating   0          10s
postgres-0                                  0/1     ContainerCreating   0          5s
producer-6b9c8d7f5e-8jhg7                   0/1     Init:0/1            0          3s
spark-master-5c4d6e8f9a-2nkl3               0/1     ContainerCreating   0          8s
spark-processor-68cb7dcd78-7w2wm            0/1     Init:0/1            0          3s
spark-worker-7f8g9h0i1j-6mlp4               0/1     Pending             0          8s
spark-worker-7f8g9h0i1j-9qrs5               0/1     Pending             0          8s
strimzi-cluster-operator-586d796fb5-b7pnr   1/1     Running             0          3m
```

**Output m·∫´u (sau 2-3 ph√∫t):**
```
NAME                            READY   STATUS      RESTARTS   AGE
datanode-0                      1/1     Running     0          3m12s
datanode-1                      1/1     Running     0          2m45s
grafana-7d5b8f6c9d-4xk2m        1/1     Running     0          3m15s
kafka-0                         1/1     Running     0          3m20s
namenode-0                      1/1     Running     0          3m22s
postgres-0                      1/1     Running     0          3m15s
producer-6b9c8d7f5e-8jhg7       1/1     Running     0          2m58s
spark-master-5c4d6e8f9a-2nkl3   1/1     Running     0          3m18s
spark-processor-68cb7dcd78-7w2wm 1/1    Running     0          2m45s
spark-worker-7f8g9h0i1j-6mlp4   1/1     Running     0          3m18s
spark-worker-7f8g9h0i1j-9qrs5   1/1     Running     0          3m18s
zookeeper-0                     1/1     Running     0          3m25s
```

> ‚è±Ô∏è **Th·ªùi gian ch·ªù**: 2-5 ph√∫t ƒë·ªÉ t·∫•t c·∫£ pods Running

**Nh·∫•n Ctrl+C ƒë·ªÉ tho√°t watch mode**

---

### 4.4 Ki·ªÉm tra t·∫•t c·∫£ resources

```powershell
# Gi·∫£i th√≠ch: Hi·ªÉn th·ªã t·∫•t c·∫£ Kubernetes resources (pods, services, deployments, statefulsets, jobs)
kubectl get all
```

**Output m·∫´u:**
```
NAME                                READY   STATUS      RESTARTS   AGE
pod/datanode-0                      1/1     Running     0          5m
pod/datanode-1                      1/1     Running     0          4m
pod/grafana-7d5b8f6c9d-4xk2m        1/1     Running     0          5m
pod/kafka-0                         1/1     Running     0          6m
pod/namenode-0                      1/1     Running     0          6m
pod/postgres-0                      1/1     Running     0          5m
pod/producer-6b9c8d7f5e-8jhg7       1/1     Running     0          4m
pod/spark-master-5c4d6e8f9a-2nkl3   1/1     Running     0          5m
pod/spark-processor-68cb7dcd78-7w2wm 1/1    Running     0          4m
pod/spark-worker-7f8g9h0i1j-6mlp4   1/1     Running     0          5m
pod/spark-worker-7f8g9h0i1j-9qrs5   1/1     Running     0          5m
pod/zookeeper-0                     1/1     Running     0          6m

NAME                     TYPE        CLUSTER-IP      EXTERNAL-IP   PORT(S)                      AGE
service/datanode         ClusterIP   None            <none>        9864/TCP                     6m
service/grafana          NodePort    10.96.45.123    <none>        3000:30300/TCP               5m
service/kafka            ClusterIP   10.96.78.234    <none>        9092/TCP,29092/TCP           6m
service/kafka-headless   ClusterIP   None            <none>        9092/TCP,29092/TCP           6m
service/namenode         NodePort    10.96.12.345    <none>        9000:30900/TCP,9870:30870/TCP 6m
service/postgres         ClusterIP   10.96.56.789    <none>        5432/TCP                     5m
service/spark-master     NodePort    10.96.89.012    <none>        7077:30077/TCP,8080:30080/TCP 5m
service/spark-processor  ClusterIP   None            <none>        7078/TCP,7079/TCP            5m
service/spark-worker     ClusterIP   None            <none>        8081/TCP                     5m
service/zookeeper        ClusterIP   10.96.23.456    <none>        2181/TCP,2888/TCP,3888/TCP   6m

NAME                           READY   UP-TO-DATE   AVAILABLE   AGE
deployment.apps/grafana        1/1     1            1           5m
deployment.apps/producer       1/1     1            1           4m
deployment.apps/spark-master   1/1     1            1           5m
deployment.apps/spark-processor 1/1    1            1           4m
deployment.apps/spark-worker   2/2     2            2           5m

NAME                                      DESIRED   CURRENT   READY   AGE
replicaset.apps/grafana-7d5b8f6c9d        1         1         1       5m
replicaset.apps/producer-6b9c8d7f5e       1         1         1       4m
replicaset.apps/spark-master-5c4d6e8f9a   1         1         1       5m
replicaset.apps/spark-processor-68cb7dcd78 1        1         1       4m
replicaset.apps/spark-worker-7f8g9h0i1j   2         2         2       5m

NAME                         READY   AGE
statefulset.apps/datanode    2/2     5m
statefulset.apps/kafka       1/1     6m
statefulset.apps/namenode    1/1     6m
statefulset.apps/postgres    1/1     5m
statefulset.apps/zookeeper   1/1     6m
```

---

### 4.5 Ki·ªÉm tra PersistentVolumeClaims

```powershell
# Gi·∫£i th√≠ch: Hi·ªÉn th·ªã PersistentVolumeClaims (PVCs) ƒë·ªÉ x√°c nh·∫≠n storage ƒë√£ ƒë∆∞·ª£c bind
kubectl get pvc
```

**Output m·∫´u:**
```
NAME                        STATUS   VOLUME         CAPACITY   ACCESS MODES   STORAGECLASS   AGE
data-datanode-0             Bound    datanode-pv    10Gi       RWO            standard       5m
data-datanode-1             Bound    pvc-abc123     10Gi       RWO            standard       4m
data-kafka-0                Bound    kafka-pv       10Gi       RWO            standard       6m
data-postgres-0             Bound    postgres-pv    5Gi        RWO            standard       5m
datalog-zookeeper-0         Bound    pvc-def456     1Gi        RWO            standard       6m
logs-zookeeper-0            Bound    pvc-ghi789     1Gi        RWO            standard       6m
name-namenode-0             Bound    namenode-pv    10Gi       RWO            standard       6m
```

---

## 5Ô∏è‚É£ B∆Ø·ªöC 5: Xem Logs & Verify Data Flow

### 5.1 Ki·ªÉm tra Producer logs

```powershell
# Gi·∫£i th√≠ch: Hi·ªÉn th·ªã 50 d√≤ng logs cu·ªëi c·ªßa Producer v√† theo d√µi realtime (-f = follow)
kubectl logs -f deployment/producer --tail=50
```

**Output m·∫´u:**
```
Connecting to Kafka at kafka:29092...
Kafka connection established successfully
Fetching air quality data from OpenWeather API...
API Key: *********************abc
City: Hanoi
Publishing message to topic: air_quality
{"timestamp": "2026-01-12T15:30:00", "aqi": 156, "pm25": 45.2, "pm10": 89.1, "co": 0.8, "no2": 32.5, "o3": 45.1}
Message published successfully
Sleeping for 60 seconds...

Publishing message to topic: air_quality
{"timestamp": "2026-01-12T15:31:00", "aqi": 158, "pm25": 46.1, "pm10": 90.3, "co": 0.9, "no2": 33.2, "o3": 44.8}
Message published successfully
Sleeping for 60 seconds...
```

---

### 5.2 Ki·ªÉm tra Kafka logs (Strimzi)

```powershell
# Gi·∫£i th√≠ch: Hi·ªÉn th·ªã 30 d√≤ng logs cu·ªëi c·ªßa Kafka broker pod
kubectl logs pod/air-quality-kafka-air-quality-pool-0 --tail=30
```

**Output m·∫´u:**
```
[2026-01-12 15:30:15,234] INFO [KafkaServer id=0] started (kafka.server.KafkaServer)
[2026-01-12 15:30:15,456] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions Set(air-quality-0) (kafka.server.ReplicaFetcherManager)
[2026-01-12 15:30:45,678] INFO [GroupCoordinator 0]: Preparing to rebalance group spark-kafka-consumer with old generation 1 (kafka.coordinator.group.GroupCoordinator)
[2026-01-12 15:30:45,890] INFO [GroupCoordinator 0]: Assignment received from leader for group spark-kafka-consumer for generation 2 (kafka.coordinator.group.GroupCoordinator)
[2026-01-12 15:31:00,123] INFO [Log partition=air-quality-0, dir=/opt/kafka/data] Rolled new log segment at offset 1234 (kafka.log.Log)
```

**Verify Kafka topics:**
```powershell
# Gi·∫£i th√≠ch: Li·ªát k√™ t·∫•t c·∫£ topics trong Kafka cluster (k·∫øt n·ªëi t·ª´ b√™n trong pod)
kubectl exec -it air-quality-kafka-air-quality-pool-0 -- /opt/kafka/bin/kafka-topics.sh --list --bootstrap-server localhost:29092
```

**Output m·∫´u:**
```
air-quality
__consumer_offsets
__strimzi_store_topic
__strimzi-topic-operator-kstreams-topic-store-changelog
```

**Xem chi ti·∫øt topic:**
```powershell
# Gi·∫£i th√≠ch: Hi·ªÉn th·ªã chi ti·∫øt topic air-quality (partitions, replicas, leader)
kubectl exec -it air-quality-kafka-air-quality-pool-0 -- /opt/kafka/bin/kafka-topics.sh --describe --topic air-quality --bootstrap-server localhost:29092
```

**Output m·∫´u:**
```
Topic: air-quality      PartitionCount: 1       ReplicationFactor: 1    Configs: 
        Topic: air-quality      Partition: 0    Leader: 0       Replicas: 0     Isr: 0
```

**Consume messages (test):**
```powershell
# Gi·∫£i th√≠ch: ƒê·ªçc 5 messages t·ª´ ƒë·∫ßu topic air_quality_data ƒë·ªÉ ki·ªÉm tra d·ªØ li·ªáu
# L∆∞u √Ω: Thay air_quality_data b·∫±ng t√™n topic b·∫°n mu·ªën ki·ªÉm tra
kubectl exec -it air-quality-kafka-air-quality-pool-0 -- /opt/kafka/bin/kafka-console-consumer.sh --bootstrap-server localhost:29092 --topic air_quality_data --from-beginning --max-messages 5
```

**Output m·∫´u:**
```
{"timestamp":"2026-01-12T15:30:00","aqi":156,"pm25":45.2,"pm10":89.1,"co":0.8,"no2":32.5,"o3":45.1}
{"timestamp":"2026-01-12T15:31:00","aqi":158,"pm25":46.1,"pm10":90.3,"co":0.9,"no2":33.2,"o3":44.8}
{"timestamp":"2026-01-12T15:32:00","aqi":159,"pm25":47.3,"pm10":91.2,"co":1.0,"no2":34.1,"o3":43.5}
Processed a total of 5 messages
```

---

### 5.3 Ki·ªÉm tra Spark Processor Deployment

```powershell
# Gi·∫£i th√≠ch: T√¨m pod c·ªßa spark-processor deployment ƒë·ªÉ l·∫•y t√™n cho l·ªánh xem logs
kubectl get pods | findstr spark-processor
```

**Output:**
```
spark-processor-68cb7dcd78-7w2wm     1/1     Running   0          10m
```

**Xem logs:**
```powershell
# Gi·∫£i th√≠ch: Hi·ªÉn th·ªã 100 d√≤ng logs cu·ªëi c·ªßa Spark Processor deployment
# L∆∞u √Ω: THAY "ten-spark-processor" b·∫±ng t√™n pod th·ª±c t·∫ø l·∫•y ƒë∆∞·ª£c ·ªü l·ªánh tr√™n
kubectl logs ten-spark-processor --tail=100

# Ho·∫∑c xem logs realtime
kubectl logs -f deployment/spark-processor --tail=50
```

**Output m·∫´u:**
```
26/01/12 15:32:10 INFO SparkContext: Running Spark version 3.0.0
26/01/12 15:32:12 INFO ResourceUtils: Using Spark default resources file
26/01/12 15:32:15 INFO SparkContext: Submitted application: AirQualityStreaming
26/01/12 15:32:18 INFO Utils: Successfully started service 'sparkDriver' on port 35217
26/01/12 15:32:20 INFO KafkaSourceProvider: Kafka source starting with options: Map(kafka.bootstrap.servers -> kafka:29092, subscribe -> air_quality)
26/01/12 15:32:25 INFO ConsumerConfig: ConsumerConfig values:
        bootstrap.servers = [kafka:29092]
        group.id = spark-kafka-source-12345
26/01/12 15:32:30 INFO StreamingQuery: Starting streaming query [id = abc-123-def, runId = ghi-456-jkl]
26/01/12 15:32:35 INFO MicroBatchExecution: Streaming query made progress: {
  "timestamp" : "2026-01-12T15:32:35.123Z",
  "batchId" : 0,
  "numInputRows" : 15,
  "processedRowsPerSecond" : 25.5
}
26/01/12 15:33:00 INFO MicroBatchExecution: Batch 1 committed
26/01/12 15:33:00 INFO PostgreSQL: Inserted 15 records to air_quality_data table
26/01/12 15:33:05 INFO HDFS: Wrote parquet file to hdfs://namenode:9000/data/air_quality_v2/batch_001.parquet
```

---

### 5.4 Ki·ªÉm tra HDFS data

```powershell
# Gi·∫£i th√≠ch: Li·ªát k√™ c√°c files trong th∆∞ m·ª•c /data/air_quality_v2 tr√™n HDFS ƒë·ªÉ x√°c nh·∫≠n Spark ƒë√£ ghi d·ªØ li·ªáu
kubectl exec -it namenode-0 -- hdfs dfs -ls /data/air_quality_v2
```

**Output m·∫´u:**
```
Found 5 items
-rw-r--r--   2 root supergroup    4523234 2026-01-12 15:33 /data/air_quality_v2/batch_001.parquet
-rw-r--r--   2 root supergroup    4512890 2026-01-12 15:34 /data/air_quality_v2/batch_002.parquet
-rw-r--r--   2 root supergroup    4534567 2026-01-12 15:35 /data/air_quality_v2/batch_003.parquet
drwxr-xr-x   - root supergroup          0 2026-01-12 15:35 /data/air_quality_v2/_spark_metadata
```

---

### 5.5 Ki·ªÉm tra PostgreSQL data

```powershell
# Gi·∫£i th√≠ch: ƒê·∫øm s·ªë records trong b·∫£ng air_quality_final ƒë·ªÉ x√°c nh·∫≠n Spark ƒë√£ insert d·ªØ li·ªáu
kubectl exec -it postgres-0 -- psql -U admin -d air_quality -c "SELECT COUNT(*) FROM air_quality_final;"
```

**Output m·∫´u:**
```
 count
-------
   456
(1 row)
```

**Xem 5 records m·ªõi nh·∫•t:**
```powershell
# Gi·∫£i th√≠ch: L·∫•y 5 records g·∫ßn ƒë√¢y nh·∫•t ƒë·ªÉ ki·ªÉm tra d·ªØ li·ªáu ch·∫•t l∆∞·ª£ng kh√¥ng kh√≠
kubectl exec -it postgres-0 -- psql -U admin -d air_quality -c "SELECT * FROM air_quality_final ORDER BY ingested_at DESC LIMIT 5;"
```

**Output m·∫´u:**
```
          timestamp          | aqi  | pm25 | pm10 |  co  | no2  |  o3
-----------------------------+------+------+------+------+------+------
 2026-01-12 15:35:00+00      |  158 | 46.1 | 90.3 |  0.9 | 33.2 | 44.8
 2026-01-12 15:34:00+00      |  156 | 45.2 | 89.1 |  0.8 | 32.5 | 45.1
 2026-01-12 15:33:00+00      |  159 | 47.3 | 91.2 |  1.0 | 34.1 | 43.5
 2026-01-12 15:32:00+00      |  155 | 44.8 | 88.7 |  0.7 | 31.9 | 45.6
 2026-01-12 15:31:00+00      |  157 | 45.9 | 89.8 |  0.8 | 32.8 | 44.2
(5 rows)
```

---

## 6Ô∏è‚É£ B∆Ø·ªöC 6: Truy C·∫≠p Dashboards

### 6.1 L·∫•y URLs c·ªßa Services

```powershell
# Gi·∫£i th√≠ch: Hi·ªÉn th·ªã danh s√°ch services v√† ports ƒë·ªÉ bi·∫øt c√°ch truy c·∫≠p UI
kubectl get svc
```

**Output m·∫´u:**
```
NAME             TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                         AGE
grafana          NodePort    10.96.45.123     <none>        3000:30300/TCP                  15m
namenode         NodePort    10.96.12.345     <none>        9000:30900/TCP,9870:30870/TCP   15m
spark-master     NodePort    10.96.89.012     <none>        7077:30077/TCP,8080:30080/TCP   15m
```

**L·∫•y Minikube IP:**
```powershell
minikube ip
```

**Output:**
```
192.168.49.2
```

---

### 6.2 M·ªü Grafana Dashboard

**Option 1: D√πng minikube service (t·ª± ƒë·ªông m·ªü browser)**
```powershell
# Gi·∫£i th√≠ch: M·ªü Grafana dashboard trong browser m·∫∑c ƒë·ªãnh, Minikube t·ª± ƒë·ªông t·∫°o tunnel
minikube service grafana -n air-quality
```

**Output m·∫´u:**
```
|---------------|---------|-------------|---------------------------|
|   NAMESPACE   |  NAME   | TARGET PORT |            URL            |
|---------------|---------|-------------|---------------------------|
| air-quality   | grafana |        3000 | http://192.168.49.2:30300 |
|---------------|---------|-------------|---------------------------|
üéâ  Opening service air-quality/grafana in default browser...
```

**Option 2: Truy c·∫≠p manual**
```
URL: http://192.168.49.2:30300
Username: admin
Password: admin123
```

**Browser s·∫Ω m·ªü t·ª± ƒë·ªông!**

---

### 6.3 M·ªü HDFS NameNode UI

```powershell
# Gi·∫£i th√≠ch: M·ªü HDFS NameNode web UI ƒë·ªÉ xem HDFS files, datanodes, cluster health
minikube service namenode -n air-quality
```

**Output m·∫´u:**
```
|---------------|----------|-------------|---------------------------|
|   NAMESPACE   |   NAME   | TARGET PORT |            URL            |
|---------------|----------|-------------|---------------------------|
| air-quality   | namenode | http/9870   | http://192.168.49.2:30870 |
|               |          | hdfs/9000   | http://192.168.49.2:30900 |
|---------------|----------|-------------|---------------------------|
üéâ  Opening service air-quality/namenode in default browser...
```

**Ho·∫∑c truy c·∫≠p:**
```
URL: http://192.168.49.2:30870
```

---

### 6.4 M·ªü Spark Master UI

```powershell
# Gi·∫£i th√≠ch: M·ªü Spark Master web UI ƒë·ªÉ xem workers, running applications, job progress
minikube service spark-master -n air-quality
```

**Output m·∫´u:**
```
|---------------|--------------|-------------|---------------------------|
|   NAMESPACE   |     NAME     | TARGET PORT |            URL            |
|---------------|--------------|-------------|---------------------------|
| air-quality   | spark-master | rpc/7077    | http://192.168.49.2:30077 |
|               |              | http/8080   | http://192.168.49.2:30080 |
|---------------|--------------|-------------|---------------------------|
üéâ  Opening service air-quality/spark-master in default browser...
```

**Web UI:**
```
URL: http://192.168.49.2:30080
```

---

### 6.5 Port-forward PostgreSQL (n·∫øu c·∫ßn k·∫øt n·ªëi t·ª´ tools)

```powershell
# Gi·∫£i th√≠ch: Chuy·ªÉn ti·∫øp port 5432 c·ªßa PostgreSQL pod ƒë·∫øn localhost:5432 ƒë·ªÉ k·∫øt n·ªëi b·∫±ng DB tools
# L∆∞u √Ω: Gi·ªØ terminal n√†y m·ªü, n·∫øu ƒë√≥ng th√¨ m·∫•t k·∫øt n·ªëi
kubectl port-forward svc/postgres 5432:5432
```

**Output m·∫´u:**
```
Forwarding from 127.0.0.1:5432 -> 5432
Forwarding from [::1]:5432 -> 5432
```

**Connection string:**
```
Host: localhost
Port: 5432
Database: air_quality
Username: admin
Password: password123
```

> üí° Gi·ªØ terminal n√†y m·ªü ƒë·ªÉ duy tr√¨ port-forward!

---

## 7Ô∏è‚É£ B∆Ø·ªöC 7: Ch·∫°y Streamlit Dashboard

### 7.1 C√†i ƒë·∫∑t Python dependencies (n·∫øu ch∆∞a c√≥)

```powershell
# Gi·∫£i th√≠ch: T·∫°o Python virtual environment ƒë·ªÉ c√¥ l·∫≠p packages kh·ªèi h·ªá th·ªëng
python -m venv .venv

# Gi·∫£i th√≠ch: K√≠ch ho·∫°t virtual environment (sau khi activate, prompt s·∫Ω c√≥ (.venv) ·ªü ƒë·∫ßu)
.\.venv\Scripts\Activate.ps1
```

**Output:**
```
(.venv) PS D:\BigData\bigdata>
```

**C√†i packages:**
```powershell
# Gi·∫£i th√≠ch: C√†i ƒë·∫∑t c√°c th∆∞ vi·ªán Python c·∫ßn thi·∫øt cho Streamlit dashboard
pip install -r requirements.txt
```

**Output m·∫´u:**
```
Collecting streamlit
  Downloading streamlit-1.40.2-py2.py3-none-any.whl (8.7 MB)
     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 8.7/8.7 MB 5.2 MB/s eta 0:00:00
Collecting pandas
  Downloading pandas-2.2.3-cp39-cp39-win_amd64.whl (11.6 MB)
     ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 11.6/11.6 MB 6.8 MB/s eta 0:00:00
...
Successfully installed streamlit-1.40.2 pandas-2.2.3 psycopg2-binary-2.9.10
```

---

### 7.2 Ch·∫°y Dashboard

```powershell
# Gi·∫£i th√≠ch: Kh·ªüi ƒë·ªông Streamlit web server v·ªõi dashboard_v2.py, browser t·ª± ƒë·ªông m·ªü
streamlit run dashboard_v2.py
```

**Output m·∫´u:**
```
  You can now view your Streamlit app in your browser.

  Local URL: http://localhost:8501
  Network URL: http://192.168.1.105:8501

  For better performance, install the Watchdog module:

  $ pip install watchdog
```

**Browser t·ª± ƒë·ªông m·ªü:** http://localhost:8501

---

## 8Ô∏è‚É£ Monitoring & Troubleshooting

### 8.1 Ki·ªÉm tra Resource Usage

```powershell
# Gi·∫£i th√≠ch: Hi·ªÉn th·ªã CPU v√† Memory usage c·ªßa Minikube node (c·∫ßn metrics-server addon)
kubectl top nodes
```

**Output m·∫´u:**
```
NAME       CPU(cores)   CPU%   MEMORY(bytes)   MEMORY%
minikube   1245m        31%    6234Mi          76%
```

**Pods resource usage:**
```powershell
# Gi·∫£i th√≠ch: Hi·ªÉn th·ªã CPU v√† Memory usage c·ªßa t·ª´ng pod trong namespace hi·ªán t·∫°i
kubectl top pods
```

**Output m·∫´u:**
```
NAME                            CPU(cores)   MEMORY(bytes)
datanode-0                      15m          512Mi
datanode-1                      12m          489Mi
grafana-7d5b8f6c9d-4xk2m        8m           156Mi
kafka-0                         45m          1024Mi
namenode-0                      25m          768Mi
postgres-0                      18m          234Mi
producer-6b9c8d7f5e-8jhg7       5m           128Mi
spark-master-5c4d6e8f9a-2nkl3   32m          512Mi
spark-worker-7f8g9h0i1j-6mlp4   28m          678Mi
spark-worker-7f8g9h0i1j-9qrs5   30m          712Mi
zookeeper-0                     10m          256Mi
```

---

### 8.2 Debug Pod kh√¥ng ch·∫°y

**Xem describe ƒë·ªÉ t√¨m l·ªói:**
```powershell
# Gi·∫£i th√≠ch: Hi·ªÉn th·ªã chi ti·∫øt pod bao g·ªìm events, resource requests/limits, l·ªói pull image, v.v.
# L∆∞u √Ω: THAY <pod-name> b·∫±ng t√™n pod th·ª±c t·∫ø (l·∫•y t·ª´ kubectl get pods)
kubectl describe pod <pod-name>
```

**Output m·∫´u (l·ªói):**
```
Events:
  Type     Reason     Age                From               Message
  ----     ------     ----               ----               -------
  Warning  Failed     2m (x5 over 5m)    kubelet            Failed to pull image "air-producer:latest": image not found
  Warning  BackOff    1m (x10 over 4m)   kubelet            Back-off pulling image "air-producer:latest"
```

**Gi·∫£i ph√°p:** Build l·∫°i image trong Minikube Docker environment

---

### 8.3 Xem Events c·ªßa cluster

```powershell
# Gi·∫£i th√≠ch: Hi·ªÉn th·ªã 20 events g·∫ßn ƒë√¢y nh·∫•t trong cluster ƒë·ªÉ debug l·ªói
kubectl get events --sort-by='.lastTimestamp' | Select-Object -Last 20
```

**Output m·∫´u:**
```
LAST SEEN   TYPE      REASON              OBJECT                          MESSAGE
2m          Normal    Scheduled           pod/producer-abc123             Successfully assigned air-quality/producer-abc123 to minikube
2m          Normal    Pulling             pod/producer-abc123             Pulling image "air-producer:latest"
2m          Normal    Pulled              pod/producer-abc123             Successfully pulled image "air-producer:latest"
2m          Normal    Created             pod/producer-abc123             Created container producer
2m          Normal    Started             pod/producer-abc123             Started container producer
1m          Warning   Unhealthy           pod/kafka-0                     Liveness probe failed: connection refused
```

---

### 8.4 Restart m·ªôt Pod

```powershell
# Gi·∫£i th√≠ch: Restart t·∫•t c·∫£ pods c·ªßa deployment producer (Kubernetes t·ª± ƒë·ªông t·∫°o pods m·ªõi)
kubectl rollout restart deployment/producer
```

**Output:**
```
deployment.apps/producer restarted
```

---

### 8.5 Scale Services

**Scale Producer:**
```powershell
# Gi·∫£i th√≠ch: TƒÉng s·ªë replicas c·ªßa producer l√™n 2 ƒë·ªÉ ch·∫°y 2 pods song song
kubectl scale deployment producer --replicas=2
```

**Output:**
```
deployment.apps/producer scaled
```

**Verify:**
```powershell
kubectl get pods | findstr producer
```

**Output:**
```
producer-6b9c8d7f5e-8jhg7       1/1     Running   0          15m
producer-6b9c8d7f5e-9xyz2       1/1     Running   0          10s
```

---

## 9Ô∏è‚É£ Clean Up & Reset

### 9.1 X√≥a Application (gi·ªØ Minikube)

```powershell
# Gi·∫£i th√≠ch: X√≥a to√†n b·ªô namespace air-quality v√† t·∫•t c·∫£ resources b√™n trong (pods, services, pvc, ...)
kubectl delete namespace air-quality
```

**Output:**
```
namespace "air-quality" deleted
```

---

### 9.2 Stop Minikube

```powershell
# Gi·∫£i th√≠ch: D·ª´ng Minikube cluster (gi·ªØ d·ªØ li·ªáu, c√≥ th·ªÉ start l·∫°i sau)
minikube stop
```

**Output:**
```
‚úã  Stopping node "minikube"  ...
üõë  Powering off "minikube" via SSH ...
üõë  1 node stopped.
```

---

### 9.3 Delete Minikube Cluster

```powershell
# Gi·∫£i th√≠ch: X√≥a ho√†n to√†n Minikube cluster v√† t·∫•t c·∫£ d·ªØ li·ªÉu (KH√îNG th·ªÉ kh√¥i ph·ª•c)
minikube delete
```

**Output:**
```
üî•  Deleting "minikube" in docker ...
üî•  Deleting container "minikube" ...
üî•  Removing C:\Users\YourUser\.minikube\machines\minikube ...
üíÄ  Removed all traces of the "minikube" cluster.
```

---

## üîÑ Quick Command Reference

### Start Project
```powershell
# Kh·ªüi ƒë·ªông Minikube cluster
minikube start

# Deploy t·∫•t c·∫£ manifests trong th∆∞ m·ª•c k8s/
kubectl apply -f k8s/ -n air-quality

# Theo d√µi pods kh·ªüi ƒë·ªông (Ctrl+C ƒë·ªÉ tho√°t)
kubectl get pods -w
```

### Check Status
```powershell
# Ki·ªÉm tra tr·∫°ng th√°i Minikube
minikube status

# Li·ªát k√™ t·∫•t c·∫£ pods trong namespace air-quality
kubectl get pods -n air-quality

# Li·ªát k√™ t·∫•t c·∫£ services v√† ports
kubectl get svc -n air-quality
```

### View Logs
```powershell
# Xem logs Producer realtime
kubectl logs -f deployment/producer -n air-quality

# Xem logs Kafka realtime
kubectl logs -f statefulset/kafka -n air-quality
```

### Access Services
```powershell
# M·ªü Grafana dashboard trong browser
minikube service grafana -n air-quality

# M·ªü HDFS NameNode UI trong browser
minikube service namenode -n air-quality

# M·ªü Spark Master UI trong browser
minikube service spark-master -n air-quality
```

### Port Forward
```powershell
# Chuy·ªÉn ti·∫øp PostgreSQL port ƒë·∫øn localhost (gi·ªØ terminal m·ªü)
kubectl port-forward svc/postgres 5432:5432 -n air-quality

# Chuy·ªÉn ti·∫øp Grafana port ƒë·∫øn localhost (gi·ªØ terminal m·ªü)
kubectl port-forward svc/grafana 3000:3000 -n air-quality
```

### Troubleshoot
```powershell
# Xem chi ti·∫øt pod ƒë·ªÉ t√¨m l·ªói (THAY <pod-name> b·∫±ng t√™n pod th·ª±c t·∫ø)
kubectl describe pod <pod-name>

# Xem 20 events g·∫ßn ƒë√¢y nh·∫•t
kubectl get events --sort-by='.lastTimestamp'

# Xem CPU/Memory usage c·ªßa nodes
kubectl top nodes

# Xem CPU/Memory usage c·ªßa pods
kubectl top pods
```

---

## üìä Service URLs Summary

Sau khi deploy, truy c·∫≠p c√°c URL sau (thay `192.168.49.2` b·∫±ng IP c·ªßa b·∫°n):

| Service | URL | Credentials |
|---------|-----|-------------|
| **Grafana** | http://192.168.49.2:30300 | admin / admin123 |
| **HDFS NameNode UI** | http://192.168.49.2:30870 | - |
| **Spark Master UI** | http://192.168.49.2:30080 | - |
| **PostgreSQL** | localhost:5432 (sau port-forward) | admin / password123 |
| **Streamlit Dashboard** | http://localhost:8501 | - |

---

## ‚ùó Common Issues & Solutions

### **Issue 0: Kafka pod stuck in "CrashLoopBackOff" (‚úÖ RESOLVED)**

**Nguy√™n nh√¢n (tr∆∞·ªõc ƒë√¢y):** Confluent CP-Kafka image c√≥ bug trong init script - kh√¥ng t∆∞∆°ng th√≠ch v·ªõi Kubernetes env variables

**Tr·∫°ng th√°i:** ‚úÖ **ƒê√É GI·∫¢I QUY·∫æT - D√πng Strimzi Kafka Operator**

**Gi·∫£i ph√°p √°p d·ª•ng:**

```powershell
# Strimzi Kafka Operator ƒë∆∞·ª£c c√†i s·∫µn
helm list -n air-quality
# Output: strimzi-kafka-operator v0.49.1

# Kafka cluster ƒë∆∞·ª£c deploy t·ª´ kafka-strimzi.yaml
kubectl get kafka -n air-quality
# Output: air-quality-kafka

# Kafka pod ch·∫°y b√¨nh th∆∞·ªùng
kubectl get pods | findstr kafka
# Output: air-quality-kafka-air-quality-pool-0   1/1     Running
```

**T·∫°i sao Strimzi gi·∫£i quy·∫øt ƒë∆∞·ª£c:**
- ‚úÖ Kubernetes-native approach (kh√¥ng d√πng Confluent image bug)
- ‚úÖ Qu·∫£n l√Ω Kafka + Zookeeper t·ª± ƒë·ªông
- ‚úÖ Robust v√† production-ready
- ‚úÖ T·ª± ƒë·ªông handle KRaft mode (Kafka 4.0+)
- ‚úÖ Kh√¥ng c·∫ßn custom workarounds

---

### Issue 1: Pod stuck in "ImagePullBackOff"

**Nguy√™n nh√¢n:** Docker image kh√¥ng t·ªìn t·∫°i trong Minikube

**Gi·∫£i ph√°p:**
```powershell
# Point Docker to Minikube
minikube -p minikube docker-env | Invoke-Expression

# Rebuild images
docker build -t air-producer:latest ./producer
docker build -t spark-processor:latest ./spark-processor

# Verify
docker images | findstr "air-producer spark-processor"
```

---

### Issue 2: Pod stuck in "Pending"

**Nguy√™n nh√¢n:** Kh√¥ng ƒë·ªß resources

**Check:**
```powershell
kubectl describe pod <pod-name> | findstr "Insufficient"
```

**Gi·∫£i ph√°p:**
```powershell
minikube stop
minikube start --cpus=6 --memory=12288
```

---

### Issue 3: Service not accessible

**Nguy√™n nh√¢n:** NodePort kh√¥ng ho·∫°t ƒë·ªông

**Gi·∫£i ph√°p:**
```powershell
# D√πng minikube service thay v√¨ truy c·∫≠p tr·ª±c ti·∫øp IP
minikube service <service-name> -n air-quality

# Ho·∫∑c port-forward
kubectl port-forward svc/<service-name> <local-port>:<service-port>
```

---

### Issue 4: HDFS connection timeout

**Check NameNode pod:**
```powershell
kubectl get pods | findstr namenode
kubectl logs namenode-0
```

**Restart n·∫øu c·∫ßn:**
```powershell
kubectl delete pod namenode-0
# Kubernetes s·∫Ω t·ª± ƒë·ªông t·∫°o pod m·ªõi
```

---

## üí° Pro Tips

1. **TƒÉng performance Minikube:**
```powershell
minikube config set cpus 6
minikube config set memory 12288
minikube config set disk-size 50g
```

2. **Enable Kubernetes Dashboard:**
```powershell
minikube dashboard
```

3. **T·∫°o alias cho kubectl:**
```powershell
Set-Alias -Name k -Value kubectl
# Sau ƒë√≥ d√πng: k get pods
```

4. **Watch logs realtime t·ª´ nhi·ªÅu pods:**
```powershell
# C√†i Stern (log aggregator)
choco install stern

# Xem logs t·∫•t c·∫£ producer pods
stern producer -n air-quality
```

5. **Backup HDFS data:**
```powershell
kubectl exec -it namenode-0 -- hdfs dfs -get /data /backup
```

---

## üìö T√†i Li·ªáu Tham Kh·∫£o

- **Minikube Docs**: https://minikube.sigs.k8s.io/docs/
- **Kubernetes Docs**: https://kubernetes.io/docs/
- **Docker Docs**: https://docs.docker.com/
- **Kafka on K8s**: https://strimzi.io/
- **Spark on K8s**: https://spark.apache.org/docs/latest/running-on-kubernetes.html

---

## ‚úÖ Checklist Ho√†n Th√†nh

- [ ] C√†i ƒë·∫∑t Minikube, kubectl, Docker Desktop
- [ ] Start Minikube v·ªõi 4 CPUs, 8GB RAM
- [ ] Build air-producer v√† spark-processor images
- [ ] Deploy t·∫•t c·∫£ K8s manifests
- [ ] Verify t·∫•t c·∫£ pods ƒëang Running
- [ ] Ki·ªÉm tra data flow: Producer ‚Üí Kafka ‚Üí Spark ‚Üí HDFS + PostgreSQL
- [ ] Truy c·∫≠p Grafana dashboard (http://MINIKUBE_IP:30300)
- [ ] Truy c·∫≠p HDFS UI (http://MINIKUBE_IP:30870)
- [ ] Truy c·∫≠p Spark UI (http://MINIKUBE_IP:30080)
- [ ] Ch·∫°y Streamlit dashboard (http://localhost:8501)

---

**üéâ Ch√∫c b·∫°n th√†nh c√¥ng! N·∫øu g·∫∑p v·∫•n ƒë·ªÅ, xem l·∫°i ph·∫ßn Troubleshooting ho·∫∑c check logs.**

