# ğŸ“˜ Giáº£i thÃ­ch Kubernetes Manifests

## ğŸ“‘ Cáº¥u trÃºc k8s/ folder

```
k8s/
â”œâ”€â”€ 00-namespace-config.yaml    # Namespace, ConfigMap, Secret, PV
â”œâ”€â”€ 01-services.yaml            # Service definitions
â”œâ”€â”€ 02-kafka.yaml               # Kafka & Zookeeper StatefulSet
â”œâ”€â”€ 03-hadoop.yaml              # NameNode & DataNode StatefulSet
â”œâ”€â”€ 04-spark.yaml               # Spark Master & Worker Deployment
â”œâ”€â”€ 05-database.yaml            # PostgreSQL & Grafana
â””â”€â”€ 06-applications.yaml        # Producer & Spark Processor
```

---

## ğŸ“„ File 1: 00-namespace-config.yaml

### Namespace
```yaml
apiVersion: v1
kind: Namespace
metadata:
  name: air-quality
```
**Ã nghÄ©a**: Táº¡o namespace riÃªng Ä‘á»ƒ tÃ¡ch biá»‡t resources (giá»‘ng folder).

---

### ConfigMap (Hadoop Configuration)
```yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: hadoop-config
  namespace: air-quality
data:
  CORE_CONF_fs_defaultFS: "hdfs://namenode:9000"
  HDFS_CONF_dfs_replication: "1"
```
**Ã nghÄ©a**: LÆ°u trá»¯ config files (non-secret) dÆ°á»›i dáº¡ng key-value.
- `CORE_CONF_*` = core-site.xml configuration
- `HDFS_CONF_*` = hdfs-site.xml configuration
- Pods sá»­ dá»¥ng: `envFrom: - configMapRef: name: hadoop-config`

---

### Secret (PostgreSQL Credentials)
```yaml
apiVersion: v1
kind: Secret
metadata:
  name: postgres-secret
  namespace: air-quality
type: Opaque
stringData:
  POSTGRES_USER: admin
  POSTGRES_PASSWORD: password123
  POSTGRES_DB: air_quality
```
**Ã nghÄ©a**: LÆ°u trá»¯ sensitive data (máº­t kháº©u, API keys).
- `type: Opaque` = base64 encoded
- Pods sá»­ dá»¥ng: `envFrom: - secretRef: name: postgres-secret`

---

### PersistentVolume (Storage)
```yaml
apiVersion: v1
kind: PersistentVolume
metadata:
  name: namenode-pv
spec:
  capacity:
    storage: 20Gi
  accessModes:
    - ReadWriteOnce
  hostPath:
    path: "/data/namenode"
```
**Ã nghÄ©a**: Táº¡o storage trÃªn host Minikube.
- `capacity: 20Gi` = dung lÆ°á»£ng
- `hostPath` = lÆ°u trá»¯ trÃªn Minikube VM
- Pods sá»­ dá»¥ng: `volumeClaimTemplates` hoáº·c `PersistentVolumeClaim`

---

## ğŸ“„ File 2: 01-services.yaml

### Service (Expose Pod)
```yaml
apiVersion: v1
kind: Service
metadata:
  name: kafka
  namespace: air-quality
spec:
  type: ClusterIP
  ports:
    - port: 29092
      targetPort: 29092
      name: internal
  selector:
    app: kafka
```
**Ã nghÄ©a**: Táº¡o endpoint Ä‘á»ƒ pods khÃ¡c káº¿t ná»‘i.
- `type: ClusterIP` = chá»‰ trong cluster (máº·c Ä‘á»‹nh)
- `type: NodePort` = expose ra bÃªn ngoÃ i (cho web UI)
- `ports.port` = port service (trong cluster)
- `ports.targetPort` = port pod (thá»±c táº¿)
- `selector` = chá»n pods nÃ o (label matching)

**VÃ­ dá»¥ káº¿t ná»‘i**:
```python
# Tá»« pod khÃ¡c, káº¿t ná»‘i Ä‘áº¿n Kafka
producer = KafkaProducer(bootstrap_servers=['kafka:29092'])
# Kubernetes DNS tá»± Ä‘á»™ng resolve 'kafka' â†’ Service IP
```

---

### NodePort Service (Expose Web UI)
```yaml
apiVersion: v1
kind: Service
metadata:
  name: namenode
spec:
  type: NodePort
  ports:
    - port: 9870
      targetPort: 9870
      nodePort: 30870  # Truy cáº­p tá»« host
```
**Ã nghÄ©a**: Expose port ra ngoÃ i cluster.
- Truy cáº­p: `http://minikube-ip:30870`
- Minikube sáº½ forward port 30870 â†’ pod port 9870

---

## ğŸ“„ File 3: 02-kafka.yaml

### StatefulSet (For Kafka & Zookeeper)
```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: kafka
spec:
  serviceName: kafka-headless  # Headless service cho DNS
  replicas: 1
  selector:
    matchLabels:
      app: kafka
  template:
    metadata:
      labels:
        app: kafka
    spec:
      containers:
      - name: kafka
        image: confluentinc/cp-kafka:7.4.0
        ports:
        - containerPort: 29092
        env:
        - name: KAFKA_BROKER_ID
          value: "1"
        volumeMounts:
        - name: kafka-data
          mountPath: /var/lib/kafka/data
  volumeClaimTemplates:
  - metadata:
      name: kafka-data
    spec:
      accessModes: [ "ReadWriteOnce" ]
      resources:
        requests:
          storage: 10Gi
```

**Ã nghÄ©a**: StatefulSet dÃ¹ng cho stateful apps (database, message queue).
- `serviceName` = headless service (DNS stable)
- `volumeClaimTemplates` = tá»± Ä‘á»™ng táº¡o PVC cho má»—i replica
- Stable hostname: `kafka-0.kafka-headless.air-quality.svc.cluster.local`
- Dá»¯ liá»‡u persist ngay cáº£ khi pod restart

---

## ğŸ“„ File 4: 03-hadoop.yaml

### NameNode StatefulSet
```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: namenode
spec:
  serviceName: namenode
  replicas: 1
  template:
    spec:
      containers:
      - name: namenode
        image: bde2020/hadoop-namenode:2.0.0-hadoop3.2.1-java8
        envFrom:
        - configMapRef:
            name: hadoop-config  # DÃ¹ng ConfigMap á»Ÿ file 00
        volumeMounts:
        - name: namenode-data
          mountPath: /hadoop/dfs/name
```

**Ã nghÄ©a**:
- `envFrom: configMapRef` = táº£i táº¥t cáº£ config tá»« ConfigMap
- `volumeMounts` = gáº¯n storage vÃ o pod
- NameNode lÆ°u metadata filesystem trÃªn `namenode-data` volume

---

### DataNode StatefulSet
```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: datanode
spec:
  replicas: 2  # 2 DataNodes
  template:
    spec:
      initContainers:
      - name: wait-for-namenode
        image: busybox:1.35
        command:
        - sh
        - -c
        - |
          until nc -z namenode 9870; do
            sleep 2
          done
```

**Ã nghÄ©a**:
- `replicas: 2` = táº¡o 2 DataNode pods (datanode-0, datanode-1)
- `initContainers` = cháº¡y trÆ°á»›c container chÃ­nh (wait for NameNode)
- `nc -z namenode 9870` = kiá»ƒm tra NameNode sáºµn sÃ ng

---

## ğŸ“„ File 5: 04-spark.yaml

### Deployment (For Spark Master & Worker)
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-master
spec:
  replicas: 1
  selector:
    matchLabels:
      app: spark-master
  template:
    metadata:
      labels:
        app: spark-master
    spec:
      containers:
      - name: spark-master
        image: bde2020/spark-master:3.0.0-hadoop3.2
        resources:
          requests:
            memory: "1Gi"
            cpu: "500m"
          limits:
            memory: "2Gi"
            cpu: "1000m"
```

**Ã nghÄ©a**: Deployment dÃ¹ng cho stateless apps.
- KhÃ´ng cáº§n `volumeClaimTemplates`
- Dá»… scale: `kubectl scale deployment spark-worker --replicas=5`
- `requests` = tá»‘i thiá»ƒu cáº§n thiáº¿t
- `limits` = maximum cho phÃ©p

---

## ğŸ“„ File 6: 05-database.yaml

### StatefulSet (PostgreSQL)
```yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: postgres
spec:
  serviceName: postgres
  replicas: 1
  template:
    spec:
      containers:
      - name: postgres
        image: postgres:13
        envFrom:
        - secretRef:
            name: postgres-secret  # DÃ¹ng Secret
        volumeMounts:
        - name: postgres-data
          mountPath: /var/lib/postgresql/data
        livenessProbe:
          exec:
            command:
            - /bin/sh
            - -c
            - pg_isready -U admin
          initialDelaySeconds: 30
          periodSeconds: 10
```

**Ã nghÄ©a**:
- `secretRef` = táº£i biáº¿n tá»« Secret (máº­t kháº©u)
- `livenessProbe` = kiá»ƒm tra pod cÃ²n sá»‘ng khÃ´ng, náº¿u fail â†’ restart

---

### Deployment (Grafana)
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: grafana
spec:
  replicas: 1
  template:
    spec:
      containers:
      - name: grafana
        image: grafana/grafana:latest
        env:
        - name: GF_SECURITY_ADMIN_PASSWORD
          value: "admin123"
        volumes:
        - name: grafana-storage
          emptyDir: {}  # KhÃ´ng persist (náº¿u muá»‘n persist â†’ PVC)
```

**Ã nghÄ©a**:
- `emptyDir` = lÆ°u táº¡m, máº¥t náº¿u pod restart
- Äá»ƒ persist â†’ dÃ¹ng `persistentVolumeClaim`

---

## ğŸ“„ File 7: 06-applications.yaml

### Deployment (Producer)
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: producer
spec:
  replicas: 1
  template:
    spec:
      containers:
      - name: producer
        image: air-producer:latest
        imagePullPolicy: Never  # DÃ¹ng local image (khÃ´ng pull tá»« registry)
        env:
        - name: KAFKA_BOOTSTRAP_SERVERS
          value: "kafka:29092"
      initContainers:
      - name: wait-for-kafka
        image: busybox:1.35
        command:
        - sh
        - -c
        - |
          until nc -z kafka 29092; do
            echo "Waiting for Kafka..."
            sleep 2
          done
```

**Ã nghÄ©a**:
- `imagePullPolicy: Never` = khÃ´ng fetch tá»« Docker Hub, dÃ¹ng local Minikube docker
- `initContainers` = Ä‘á»£i Kafka sáºµn sÃ ng rá»“i má»›i start producer

---

### Deployment (Spark Processor)
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: spark-processor
spec:
  replicas: 1
  template:
    spec:
      subdomain: spark-processor
      hostname: spark-processor-driver
      containers:
      - name: spark-processor
        image: spark-processor:v5
        env:
        - name: SPARK_LOCAL_HOSTNAME
          value: "spark-processor-driver.spark-processor.air-quality.svc.cluster.local"
```

**Ã nghÄ©a**:
- `Deployment` = cháº¡y liÃªn tá»¥c (streaming job)
- `subdomain` + `hostname` = táº¡o stable DNS name cho driver pod
- `SPARK_LOCAL_HOSTNAME` = FQDN Ä‘á»ƒ executors káº¿t ná»‘i driver
- Thay Ä‘á»•i tá»« Job vÃ¬ Spark streaming cáº§n cháº¡y liÃªn tá»¥c

---

### Headless Service (Spark Driver DNS)
```yaml
apiVersion: v1
kind: Service
metadata:
  name: spark-processor
spec:
  clusterIP: None  # Headless service
  selector:
    app: spark-processor
  ports:
  - name: driver-rpc
    port: 7078
  - name: blockmanager
    port: 7079
```

**Ã nghÄ©a**:
- `clusterIP: None` = headless service (khÃ´ng load balance)
- Táº¡o DNS record: `spark-processor-driver.spark-processor.air-quality.svc.cluster.local`
- Executors dÃ¹ng DNS nÃ y Ä‘á»ƒ káº¿t ná»‘i driver
- Giáº£i quyáº¿t lá»—i "UnknownHostException" khi executors káº¿t ná»‘i driver

---

## ğŸ”„ Lifecycle trong Kubernetes

```
1. Apply manifests
   kubectl apply -f k8s/

2. Create Namespace
   Namespace 'air-quality' created

3. Create ConfigMap & Secret
   ConfigMap, Secret lÆ°u trá»¯ sáºµn

4. Create PersistentVolumes
   PV '/data/namenode', '/data/datanode' etc táº¡o

5. Create Services
   Services expose pods

6. Create Zookeeper StatefulSet
   zookeeper-0 pod khá»Ÿi Ä‘á»™ng

7. Create Kafka StatefulSet
   initContainer chá» Zookeeper ready
   kafka-0 pod khá»Ÿi Ä‘á»™ng

8. Create Hadoop StatefulSet
   namenode-0 khá»Ÿi Ä‘á»™ng
   datanode-0, datanode-1 khá»Ÿi Ä‘á»™ng (chá» namenode sáºµn sÃ ng)

9. Create Spark Deployment
   spark-master khá»Ÿi Ä‘á»™ng
   spark-worker-0, spark-worker-1 khá»Ÿi Ä‘á»™ng (chá» master)

10. Create Database Deployment
    postgres-0, grafana pod khá»Ÿi Ä‘á»™ng

11. Create Applications
    producer deployment khá»Ÿi Ä‘á»™ng (chá» kafka)
    spark-processor deployment khá»Ÿi Ä‘á»™ng (chá» dependencies)
    spark-processor headless service táº¡o DNS record cho driver
```

---

## ğŸ”§ Chá»‰nh sá»­a Manifests

### Thay Ä‘á»•i replicas
```yaml
# File 04-spark.yaml
kind: Deployment
metadata:
  name: spark-worker
spec:
  replicas: 2  # Thay 2 â†’ 5 Ä‘á»ƒ cÃ³ 5 workers
```

### Thay Ä‘á»•i resources
```yaml
spec:
  template:
    spec:
      containers:
      - name: spark-worker
        resources:
          requests:
            memory: "2Gi"    # TÄƒng tá»« 1Gi
            cpu: "1000m"     # TÄƒng tá»« 500m
          limits:
            memory: "4Gi"    # TÄƒng tá»« 2Gi
```

### Thay Ä‘á»•i image
```yaml
containers:
- name: kafka
  image: confluentinc/cp-kafka:7.5.0  # Upgrade version
```

### ThÃªm environment variable
```yaml
env:
- name: KAFKA_BOOTSTRAP_SERVERS
  value: "kafka:29092"
- name: NEW_VAR           # ThÃªm
  value: "new_value"      # ThÃªm
```

---

## ğŸš€ Apply Changes

```powershell
# Ãp dá»¥ng tá»«ng file
kubectl apply -f k8s/04-spark.yaml

# Ãp dá»¥ng táº¥t cáº£
kubectl apply -f k8s/

# Xem thay Ä‘á»•i
kubectl diff -f k8s/

# Undo (rollback)
kubectl rollout undo deployment/spark-worker -n air-quality
```

---

## ğŸ“Š Kiá»ƒm tra Manifests

```powershell
# Validate YAML
kubectl apply -f k8s/ --dry-run=client

# Xem resources sáº½ Ä‘Æ°á»£c táº¡o
kubectl apply -f k8s/ --dry-run=client -o yaml

# Check differences
kubectl diff -f k8s/
```

---

## ğŸ’¡ Best Practices

1. **DÃ¹ng ConfigMap & Secret** cho config, trÃ¡nh hardcode
2. **DÃ¹ng StatefulSet** cho database, message queue
3. **DÃ¹ng Deployment** cho stateless apps
4. **ThÃªm livenessProbe & readinessProbe** Ä‘á»ƒ health check
5. **Set resource requests & limits** Ä‘á»ƒ trÃ¡nh resource starvation
6. **DÃ¹ng initContainers** Ä‘á»ƒ chá» dependencies
7. **DÃ¹ng Labels & Selectors** Ä‘á»ƒ organize resources

---

## ğŸ“– TÃ i liá»‡u Kubernetes

- [Kubernetes Objects](https://kubernetes.io/docs/concepts/overview/working-with-objects/)
- [StatefulSet vs Deployment](https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/)
- [Services](https://kubernetes.io/docs/concepts/services-networking/service/)
- [ConfigMaps & Secrets](https://kubernetes.io/docs/concepts/configuration/configmap/)
